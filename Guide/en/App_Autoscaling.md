# App Autoscaling

In the [Getting started](https://expvent.com/documentation/docs/), we have created a simple application. But when the load of this application exceeds the endurance range of computing resources, the application's service response will slow down, time out, or even be unavailable. The [EverAI](https://everai.expvent.com) platform provides an autoscaling mechanism that can help your application automatically expand under high load conditions, eliminating the need for you to manually deploy new computing nodes. This enables your application to quickly increase its load capacity in a short period of time.    

First you create a `configmap` by the following command, this `configmap` includes policy parameters about autoscaling, the example defines that the mini workers number is 1, the max workers number is 5, and the max queue size is 2.  

```bash
ever configmap create get-start-configmap \ 
  --from-literal min_workers=1 \
  --from-literal max_workers=5 \
  --from-literal max_queue_size=2 \
  --from-literal scale_up_step=1 \
  --from-literal max_idle_time=60
```
Based on the `app.py` code in [Quickstart](https://expvent.com/documentation/zh-cn/docs/), When you define tha object of app,  you should add parameter `autoscaling_policy`.  

```python
from everai.autoscaling import SimpleAutoScalingPolicy

CONFIGMAP_NAME = 'get-start-configmap'

app = App(
    '<your app name>',
    image=image,
    volume_requests=[
        VolumeRequest(name=VOLUME_NAME, create_if_not_exists=True),
    ],
    secret_requests=[QUAY_IO_SECRET_NAME],
    configmap_requests=[CONFIGMAP_NAME],
    resource_requests=ResourceRequests(
        cpu_num=1,
        memory_mb=1024,
    ),
    autoscaling_policy=SimpleAutoScalingPolicy(
        min_workers=Placeholder(kind='ConfigMap', name=CONFIGMAP_NAME, key='min_workers'),
        max_workers=Placeholder(kind='ConfigMap', name=CONFIGMAP_NAME, key='max_workers'),
        max_queue_size=Placeholder(kind='ConfigMap', name=CONFIGMAP_NAME, key='max_queue_size'),
        max_idle_time=Placeholder(kind='ConfigMap', name=CONFIGMAP_NAME, key='max_idle_time'),
        scale_up_step=Placeholder(kind='ConfigMap', name=CONFIGMAP_NAME, key='scale_up_step'),
    ),
)
```
Secondly, you run `everai app run` to check your code locally. And then open  `image_builder.py`, update your image registry's version. Run `everai image build` to buld image and push the image to [quay.io](https://quay.io/). Aftering build image, you can run the following command to upgrade your app.  

```bash
everai app upgrade --image
```
Now, your app has the ability to autoscale.  

Run `everai worker list`, you can see that there is one worker under low load conditions.

```bash
ID                      STATUS    DETAIL_STATUS    CREATED_AT                DELETED_AT
----------------------  --------  ---------------  ------------------------  ------------
ULSUfqhnsEV35JyuWiuVyo  RUNNING   FREE             2024-05-11 19:00:52+0800
```
Run `everai app queue`, you can see the queue size is 0 in the queue list.

```bash
  QUEUE_INDEX  CREATE_AT                 QUEUE_REASON
-------------  ------------------------  --------------
```

In this step, you can use `ab` to test your app's performance, and expand your app's workload. At same time, you should observe that the changes in the number of workers and queues.

```bash
ab -s 120 -t 120 -c 4 -n 300000 -H'Authorization: Bearer <your_token>' https://everai.expvent.com/api/routes/v1/<your app route name>/sse
```

During the performance test, run `everai worker list` and `everai app queue` agian, you can see the changes. Now, the queue size is 2 in queue list.  

```bash
  QUEUE_INDEX  CREATE_AT                 QUEUE_REASON
-------------  ------------------------  --------------
            0  2024-05-11 19:25:19+0800  WorkerBusy
            1  2024-05-11 19:25:28+0800  WorkerBusy
```
In the worker list, you can see 2 workers running, there is just 1 worker running before the performance test. It means that the [EverAI](https://everai.expvent.com) platform has finished the scale job for your app automatically.  
  
```bash
ID                      STATUS    DETAIL_STATUS    CREATED_AT                DELETED_AT
----------------------  --------  ---------------  ------------------------  ------------
ULSUfqhnsEV35JyuWiuVyo  RUNNING   BUSY             2024-05-11 19:00:52+0800
bqZJ4eTjMmEbP9ncrvPgGg  RUNNING   BUSY             2024-05-11 19:24:08+0800
```

When the `ab` performance test is over and the peak period of the application business load has passed, the system will automatically determine the load status of the workers. After `max_idle_time`, the workers generated by the expansion will be released and restored to the set number of `mini_workers`. In this example, by executing `everai worker list`, you can see that the number of workers in the app has returned to one worker before expansion. The system has completed the automatic scaling down operation for your app.  
 
```bash
ID                      STATUS    DETAIL_STATUS    CREATED_AT                DELETED_AT
----------------------  --------  ---------------  ------------------------  ------------
ULSUfqhnsEV35JyuWiuVyo  RUNNING   FREE             2024-05-11 19:00:52+0800
```


